
======================================================================
ULTRA-FAST KAGGLE VALIDATION PIPELINE
======================================================================

This will complete in ~5 minutes and verify:
  ✓ Data preprocessing works
  ✓ GAN training runs without errors
  ✓ Sample generation works
  ✓ Baseline comparison works

NOTE: Results will NOT be accurate (using minimal data/epochs)
======================================================================
============================================================
ENVIRONMENT INFORMATION
============================================================
✓ Running on Kaggle
✓ GPU available: Tesla P100-PCIE-16GB
  GPU memory: 17.06 GB

Available inputs:
  - brazilian-ecommerce

✓ Olist dataset found at: /kaggle/input/brazilian-ecommerce


[1/4] Using existing preprocessed data ✓

[2/4] Training GAN (~2 minutes)...
============================================================
TRAINING CONDITIONAL WGAN-GP FOR SALES FORECASTING
============================================================

Configuration:
experiment_name: cgan_ultrafast_test
seed: 42
data:
  path: /kaggle/working/processed/product_daily_panel_small.parquet
  batch_size: 16
  num_workers: 0
  history_window: 30
  forecast_horizon: 7
  train_ratio: 0.7
  val_ratio: 0.15
  use_augmentation: false
  synthetic_data_path: null
  synthetic_ratio: 1.0
model:
  noise_dim: 64
  condition_dim: 256
  hidden_dim: 64
  output_len: 7
training:
  max_epochs: 1
  lambda_gp: 10.0
  n_critic: 2
  lr_g: 0.0002
  lr_d: 0.0004
  gradient_clip_val: 0.0
trainer:
  accelerator: auto
  devices: 1
  deterministic: false
  log_every_n_steps: 5
  enable_progress_bar: true
  enable_model_summary: true
  limit_train_batches: 50
  limit_val_batches: 20
quick_run:
  enabled: true
  max_epochs: 1
  batch_size: 16
  limit_train_batches: 50
  limit_val_batches: 20
  limit_test_batches: 0.0
wandb:
  project: sales-forecasting-gan
  entity: null
  mode: disabled
checkpoint:
  monitor: g_loss
  mode: min
  save_top_k: 1
  dirpath: /kaggle/working/checkpoints
  filename: gan-ultrafast-{epoch:02d}
paths:
  data_dir: /kaggle/input
  output_dir: /kaggle/working/experiments
  checkpoints: /kaggle/working/checkpoints
  logs: /kaggle/working/logs

Seed set to 42

============================================================
INITIALIZING DATA MODULE
============================================================

============================================================
INITIALIZING WGAN-GP MODEL
============================================================

Model parameters:
  Generator: 2,372,417
  Discriminator: 2,790,529
  Total: 5,162,946

✓ TensorBoard logging enabled

============================================================
INITIALIZING TRAINER
============================================================
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores

Trainer configuration:
  Max epochs: 1
  Accelerator: auto
  Devices: 1
  Gradient clipping: 0.0
  Quick run: ENABLED
    Batch size: 16
    limit_train_batches: 50
    limit_val_batches: 20

============================================================
STARTING TRAINING
============================================================
2025-12-19 15:19:57.791167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1766157597.812068     657 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1766157597.818595     657 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1766157597.835904     657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1766157597.835937     657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1766157597.835941     657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1766157597.835945     657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
Loading data from /kaggle/working/processed/product_daily_panel_small.parquet...
Train split: 413 days, 2017-01-15 00:00:00 to 2018-03-03 00:00:00
Creating sequences for 50 products...
Created 10784 sequences for train split                                         
Loading data from /kaggle/working/processed/product_daily_panel_small.parquet...
Val split: 89 days, 2018-03-04 00:00:00 to 2018-05-31 00:00:00
Creating sequences for 49 products...
Created 2396 sequences for val split                                            
Loading data from /kaggle/working/processed/product_daily_panel_small.parquet...
Test split: 89 days, 2018-06-01 00:00:00 to 2018-08-28 00:00:00
Creating sequences for 44 products...
Created 1708 sequences for test split                                           
/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓
┃   ┃ Name          ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃
┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩
│ 0 │ generator     │ Generator     │  2.4 M │ train │     0 │
│ 1 │ discriminator │ Discriminator │  2.8 M │ train │     0 │
└───┴───────────────┴───────────────┴────────┴───────┴───────┘
Trainable params: 5.2 M                                                         
Non-trainable params: 0                                                         
Total params: 5.2 M                                                             
Total estimated model params size (MB): 20                                      
Modules in train mode: 57                                                       
Modules in eval mode: 0                                                         
Total FLOPs: 0                                                                  
/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/dat
a_connector.py:434: The 'val_dataloader' does not have many workers which may be
a bottleneck. Consider increasing the value of the `num_workers` argument` to 
`num_workers=3` in the `DataLoader` to improve performance.
/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/dat
a_connector.py:434: The 'train_dataloader' does not have many workers which may 
be a bottleneck. Consider increasing the value of the `num_workers` argument` to
`num_workers=3` in the `DataLoader` to improve performance.
/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: -- 0.00it/s v_num: 8.000
UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! 
Attempting to set the primary context... (Triggered internally at 
/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:179.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine 
to run the backward pass
Epoch 0/0  ━━━━━━━━━━━━━━━━━━ 1/50 0:00:00 • -:--:-- 0.00it/s v_num: 8.000      
                                                              d_loss: -0.001 gp:
                                                              0.976 g_loss:     
Epoch 0/0  ╸━━━━━━━━━━━━━━━━ 2/50 0:00:00 • 0:00:05 10.78it/s v_num: 8.000      
                                                              d_loss: -0.019 gp:
                                                              0.856 g_loss:     
Epoch 0/0  ━╺━━━━━━━━━━━━━━━ 3/50 0:00:00 • 0:00:05 10.80it/s v_num: 8.000      
                                                              d_loss: -0.003 gp:
                                                              0.536 g_loss:     
Epoch 0/0  ━╺━━━━━━━━━━━━━━━ 4/50 0:00:00 • 0:00:05 10.84it/s v_num: 8.000      
                                                              d_loss: -0.269 gp:
                                                              0.436 g_loss:     
Epoch 0/0  ━╸━━━━━━━━━━━━━━━ 5/50 0:00:00 • 0:00:05 10.84it/s v_num: 8.000      
                                                              d_loss: 0.041 gp: 
                                                              0.145 g_loss:     
Epoch 0/0  ━━╺━━━━━━━━━━━━━━ 6/50 0:00:00 • 0:00:05 10.86it/s v_num: 8.000      
                                                              d_loss: 0.195 gp: 
                                                              0.024 g_loss:     
Epoch 0/0  ━━╺━━━━━━━━━━━━━━ 7/50 0:00:00 • 0:00:04 10.87it/s v_num: 8.000      
                                                              d_loss: 0.103 gp: 
                                                              0.004 g_loss:     
Epoch 0/0  ━━╸━━━━━━━━━━━━━━ 8/50 0:00:01 • 0:00:04 10.90it/s v_num: 8.000      
                                                              d_loss: 0.252 gp: 
                                                              0.005 g_loss:     
Epoch 0/0  ━━━╺━━━━━━━━━━━━━ 9/50 0:00:01 • 0:00:04 10.91it/s v_num: 8.000      
                                                              d_loss: 0.141 gp: 
                                                              0.004 g_loss:     
Epoch 0/0  ━━━╺━━━━━━━━━━━━━ 10/50 0:00:01 • 0:00:04 10.89it/s v_num: 8.000     
                                                               d_loss: 0.145 gp:
                                                               0.007 g_loss:    
Epoch 0/0  ━━━╸━━━━━━━━━━━━━ 11/50 0:00:01 • 0:00:04 10.88it/s v_num: 8.000     
                                                               d_loss: 0.189 gp:
                                                               0.009 g_loss:    
Epoch 0/0  ━━━━╺━━━━━━━━━━━━ 12/50 0:00:01 • 0:00:04 10.89it/s v_num: 8.000     
                                                               d_loss: 0.071 gp:
                                                               0.004 g_loss:    
Epoch 0/0  ━━━━╺━━━━━━━━━━━━ 13/50 0:00:01 • 0:00:04 10.91it/s v_num: 8.000     
                                                               d_loss: 0.159 gp:
                                                               0.013 g_loss:    
Epoch 0/0  ━━━━╸━━━━━━━━━━━━ 14/50 0:00:01 • 0:00:04 10.91it/s v_num: 8.000     
                                                               d_loss: 0.255 gp:
                                                               0.028 g_loss:    
Epoch 0/0  ━━━━━╺━━━━━━━━━━━ 15/50 0:00:01 • 0:00:04 10.93it/s v_num: 8.000     
                                                               d_loss: 0.164 gp:
                                                               0.020 g_loss:    
Epoch 0/0  ━━━━━╺━━━━━━━━━━━ 16/50 0:00:01 • 0:00:04 10.93it/s v_num: 8.000     
                                                               d_loss: 0.206 gp:
                                                               0.012 g_loss:    
Epoch 0/0  ━━━━━╸━━━━━━━━━━━ 17/50 0:00:01 • 0:00:04 10.94it/s v_num: 8.000     
                                                               d_loss: 0.102 gp:
                                                               0.026 g_loss:    
Epoch 0/0  ━━━━━━╺━━━━━━━━━━ 18/50 0:00:01 • 0:00:03 10.94it/s v_num: 8.000     
                                                               d_loss: 0.198 gp:
                                                               0.048 g_loss:    
Epoch 0/0  ━━━━━━╺━━━━━━━━━━ 19/50 0:00:02 • 0:00:03 10.94it/s v_num: 8.000     
                                                               d_loss: 0.211 gp:
                                                               0.024 g_loss:    
Epoch 0/0  ━━━━━━╸━━━━━━━━━━ 20/50 0:00:02 • 0:00:03 10.94it/s v_num: 8.000     
                                                               d_loss: 0.240 gp:
                                                               0.009 g_loss:    
Epoch 0/0  ━━━━━━━╺━━━━━━━━━ 21/50 0:00:02 • 0:00:03 10.94it/s v_num: 8.000     
                                                               d_loss: 0.186 gp:
                                                               0.013 g_loss:    
Epoch 0/0  ━━━━━━━╺━━━━━━━━━ 22/50 0:00:02 • 0:00:03 10.92it/s v_num: 8.000     
                                                               d_loss: 0.217 gp:
                                                               0.019 g_loss:    
Epoch 0/0  ━━━━━━━╸━━━━━━━━━ 23/50 0:00:02 • 0:00:03 10.92it/s v_num: 8.000     
                                                               d_loss: 0.232 gp:
                                                               0.012 g_loss:    
Epoch 0/0  ━━━━━━━━╺━━━━━━━━ 24/50 0:00:02 • 0:00:03 10.92it/s v_num: 8.000     
                                                               d_loss: 0.096 gp:
                                                               0.011 g_loss:    
Epoch 0/0  ━━━━━━━━╸━━━━━━━━ 25/50 0:00:02 • 0:00:03 10.92it/s v_num: 8.000     
                                                               d_loss: 0.235 gp:
                                                               0.007 g_loss:    
Epoch 0/0  ━━━━━━━━╸━━━━━━━━ 26/50 0:00:02 • 0:00:03 10.92it/s v_num: 8.000     
                                                               d_loss: 0.131 gp:
                                                               0.011 g_loss:    
Epoch 0/0  ━━━━━━━━━╺━━━━━━━ 27/50 0:00:02 • 0:00:03 10.93it/s v_num: 8.000     
                                                               d_loss: 0.119 gp:
                                                               0.006 g_loss:    
Epoch 0/0  ━━━━━━━━━╸━━━━━━━ 28/50 0:00:02 • 0:00:03 10.93it/s v_num: 8.000     
                                                               d_loss: 0.128 gp:
                                                               0.017 g_loss:    
Epoch 0/0  ━━━━━━━━━╸━━━━━━━ 29/50 0:00:02 • 0:00:02 10.94it/s v_num: 8.000     
                                                               d_loss: 0.225 gp:
                                                               0.006 g_loss:    
Epoch 0/0  ━━━━━━━━━━╺━━━━━━ 30/50 0:00:03 • 0:00:02 10.94it/s v_num: 8.000     
                                                               d_loss: 0.124 gp:
                                                               0.009 g_loss:    
Epoch 0/0  ━━━━━━━━━━╸━━━━━━ 31/50 0:00:03 • 0:00:02 10.94it/s v_num: 8.000     
                                                               d_loss: 0.192 gp:
                                                               0.008 g_loss:    
Epoch 0/0  ━━━━━━━━━━╸━━━━━━ 32/50 0:00:03 • 0:00:02 10.94it/s v_num: 8.000     
                                                               d_loss: 0.085 gp:
                                                               0.008 g_loss:    
Epoch 0/0  ━━━━━━━━━━━╺━━━━━ 33/50 0:00:03 • 0:00:02 10.92it/s v_num: 8.000     
                                                               d_loss: 0.171 gp:
                                                               0.010 g_loss:    
Epoch 0/0  ━━━━━━━━━━━╸━━━━━ 34/50 0:00:03 • 0:00:02 10.92it/s v_num: 8.000     
                                                               d_loss: 0.138 gp:
                                                               0.019 g_loss:    
Epoch 0/0  ━━━━━━━━━━━╸━━━━━ 35/50 0:00:03 • 0:00:02 10.86it/s v_num: 8.000     
                                                               d_loss: 0.131 gp:
                                                               0.005 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━╺━━━━ 36/50 0:00:03 • 0:00:02 10.84it/s v_num: 8.000     
                                                               d_loss: 0.177 gp:
                                                               0.052 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━╸━━━━ 37/50 0:00:03 • 0:00:02 10.85it/s v_num: 8.000     
                                                               d_loss: 0.089 gp:
                                                               0.013 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━╸━━━━ 38/50 0:00:03 • 0:00:02 10.86it/s v_num: 8.000     
                                                               d_loss: 0.168 gp:
                                                               0.015 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━╺━━━ 39/50 0:00:03 • 0:00:02 10.86it/s v_num: 8.000     
                                                               d_loss: 0.171 gp:
                                                               0.029 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━╸━━━ 40/50 0:00:03 • 0:00:01 10.86it/s v_num: 8.000     
                                                               d_loss: 0.180 gp:
                                                               0.028 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━╸━━━ 41/50 0:00:04 • 0:00:01 10.86it/s v_num: 8.000     
                                                               d_loss: 0.182 gp:
                                                               0.021 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━╺━━ 42/50 0:00:04 • 0:00:01 10.87it/s v_num: 8.000     
                                                               d_loss: 0.166 gp:
                                                               0.042 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━╸━━ 43/50 0:00:04 • 0:00:01 10.87it/s v_num: 8.000     
                                                               d_loss: 0.143 gp:
                                                               0.059 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━╸━━ 44/50 0:00:04 • 0:00:01 10.87it/s v_num: 8.000     
                                                               d_loss: 0.151 gp:
                                                               0.041 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━╺━ 45/50 0:00:04 • 0:00:01 10.87it/s v_num: 8.000     
                                                               d_loss: 0.171 gp:
                                                               0.025 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━╸━ 46/50 0:00:04 • 0:00:01 10.88it/s v_num: 8.000     
                                                               d_loss: 0.209 gp:
                                                               0.029 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━╸━ 47/50 0:00:04 • 0:00:01 10.88it/s v_num: 8.000     
                                                               d_loss: 0.196 gp:
                                                               0.023 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━━╺ 48/50 0:00:04 • 0:00:01 10.88it/s v_num: 8.000     
                                                               d_loss: 0.116 gp:
                                                               0.013 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━━╸ 49/50 0:00:04 • 0:00:01 10.89it/s v_num: 8.000     
                                                               d_loss: 0.215 gp:
                                                               0.022 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            Epoch 0, global step 150: 'g_loss' reached 0.05250 (best 0.05250), saving model to '/kaggle/working/checkpoints/gan-ultrafast-epoch=00-v4.ckpt' as top 1
`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0/0  ━━━━━━━━━━━━━━━━━ 50/50 0:00:04 • 0:00:00 10.89it/s v_num: 8.000     
                                                               d_loss: 0.261 gp:
                                                               0.020 g_loss:    
                                                               0.053            
`weights_only` was not set, defaulting to `False`.

============================================================
TRAINING COMPLETE!
============================================================

✓ Best model checkpoint: /kaggle/working/checkpoints/gan-ultrafast-epoch=00-v4.ckpt
✓ Final model saved to: /kaggle/working/checkpoints/final_model.ckpt

============================================================
VALIDATING FINAL MODEL
============================================================
Loading data from /kaggle/working/processed/product_daily_panel_small.parquet...
Train split: 413 days, 2017-01-15 00:00:00 to 2018-03-03 00:00:00
Creating sequences for 50 products...
Created 10784 sequences for train split                                         
Loading data from /kaggle/working/processed/product_daily_panel_small.parquet...
Val split: 89 days, 2018-03-04 00:00:00 to 2018-05-31 00:00:00
Creating sequences for 49 products...
Created 2396 sequences for val split                                            
Loading data from /kaggle/working/processed/product_daily_panel_small.parquet...
Test split: 89 days, 2018-06-01 00:00:00 to 2018-08-28 00:00:00
Creating sequences for 44 products...
Created 1708 sequences for test split                                           
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓20 0:00:00 • 0:00:00 95.09it/s 2;4m95.17it/s 
┃      Validate metric      ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      val_fake_score       │   -0.04363579303026199    │
│          val_mae          │    0.05927827209234238    │
│      val_real_score       │   -0.17336995899677277    │
└───────────────────────────┴───────────────────────────┘
Validation ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20/20 0:00:00 • 0:00:00 95.09it/s 

✓ All done!